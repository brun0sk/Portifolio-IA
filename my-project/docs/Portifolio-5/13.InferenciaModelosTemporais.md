# Inferência em Modelos Temporais

Modelos temporais são amplamente utilizados em Inteligência Artificial para representar sistemas dinâmicos onde o estado do mundo evolui ao longo do tempo. A inferência nesses modelos consiste em estimar estados passados, presentes ou futuros com base em observações disponíveis.

Entre as técnicas de inferência em modelos temporais, podem ser citadas:

- Filtragem (Filtering)

- Predição (Prediction)

- Suavização (Smoothing)

- Explicação Mais Provável (Most Likely Explanation)

- Aprendizado (Learning)

## Filtragem
A filtragem consiste em estimar o estado atual 𝑋𝑡 de um sistema com base em todas as observações passadas 
$𝑂1,𝑂2,...,𝑂𝑡$. Esse processo é essencial para agentes que precisam operar em tempo real, como robôs autônomos e sistemas de rastreamento.

A equação de filtragem pode ser dada por:

$
P(X_t | O_1, O_2, ..., O_t)
$

Essa inferência pode ser realizada recursivamente usando a regra de Bayes e um modelo de transição probabilístico. Métodos comuns para filtragem incluem:

- Filtros de Kalman (para estados contínuos com ruído gaussiano).
- Filtros de Partículas (para distribuições arbitrárias de estados).
- Modelos Ocultos de Markov (HMMs) (para estados discretos).

## Predição
Na predição, o objetivo é estimar um estado futuro $𝑋𝑡+𝑘$ com base nas observações até o tempo 𝑡. A predição é útil em aplicações como previsão do tempo e controle de sistemas.

A equação de predição é dada por:

$
P(X_{t+k} | O_1, O_2, ..., O_t)
$

Ela pode ser obtida iterando sobre o modelo de transição do sistema:

$
P(X_{t+1} | O_1, ..., O_t) = \sum_{X_t} P(X_{t+1} | X_t) P(X_t | O_1, ..., O_t)
$

A predição pode ser realizada com técnicas como simulação Monte Carlo e filtros de partículas.

## Suavização

A suavização consiste em estimar a distribuição um estado passado 𝑋𝑘 para 𝑘<𝑡(estado presente).

A equação da suavização é:

$
P(X_k | e_{1:t})
$

A suavização é usada em aplicações como:

Ela pode ser realizada através de algoritmos como o algoritmo para trás (Backward Algorithm) em Modelos Ocultos de Markov.

## Explicação Mais Provável
A inferência da explicação mais provável busca encontrar a sequência de estados mais provável $𝑋1,𝑋2,...,𝑋𝑡$ que pode ter gerado uma sequência de observações $𝑂1,𝑂2,...,𝑂𝑡$.

O problema pode ser formulado como:

$
\arg\max_{X_1, ..., X_t} P(X_1, ..., X_t | O_1, ..., O_t)
$

5. Aprendizado

O aprendizado em modelos temporais envolve estimar os parâmetros do modelo de transição.

O aprendizado pode ser:

- Supervisionado, quando há estados rotulados no conjunto de treinamento.

- Não supervisionado, quando os estados são inferidos a partir das observações.

## Referências

[1] RUSSELL, Stuart; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3. ed. Upper Saddle River: Prentice Hall, 2010.

[2] THRUN, Sebastian; BURGARD, Wolfram; FOX, Dieter. Probabilistic Robotics. MIT Press, 2005.

[3] BISHOP, Christopher M. Pattern Recognition and Machine Learning. Springer, 2006.

[4] MURPHY, Kevin P. Machine Learning: A Probabilistic Perspective. MIT Press, 2012.