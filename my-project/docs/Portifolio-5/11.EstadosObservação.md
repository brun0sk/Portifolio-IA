# Estados e ObservaÃ§Ã£o

Os conceitos de estado e observaÃ§Ã£o sÃ£o fundamentais para modelar sistemas dinÃ¢micos e agentes inteligentes que interagem com o ambiente. Um agente deve ser capaz de inferir seu estado atual a partir de observaÃ§Ãµes ruidosas e tomar decisÃµes com base nessas informaÃ§Ãµes.

## DefiniÃ§Ã£o de Estado

O estado de um sistema representa todas as informaÃ§Ãµes necessÃ¡rias para descrever completamente a situaÃ§Ã£o em um determinado momento. Dependendo da natureza do sistema, os estados podem ser:

- Estados Completamente ObservÃ¡veis: O agente tem acesso a todas as informaÃ§Ãµes relevantes sobre o ambiente. Exemplos incluem jogos de tabuleiro como xadrez, onde todas as peÃ§as estÃ£o visÃ­veis.

- Estados Parcialmente ObservÃ¡veis: O agente sÃ³ recebe informaÃ§Ãµes limitadas ou ruidosas sobre o verdadeiro estado do ambiente. Isso ocorre, por exemplo, em robÃ´s autÃ´nomos que dependem de sensores para navegar.

Uma das formas de se trabalhar com incerteza em sistemas parcialmente observÃ¡veis, Ã© modelando ela apartir das distribuiÃ§Ãµes de probabilidade sobre possÃ­veis estados.

## DefiniÃ§Ã£o de ObservaÃ§Ã£o

A observaÃ§Ã£o corresponde Ã  informaÃ§Ã£o disponÃ­vel para o agente em um determinado instante. Como os sensores podem ser imprecisos, as observaÃ§Ãµes frequentemente apresentam ruÃ­do e incerteza.

A relaÃ§Ã£o entre estados reais $ğ‘‹ğ‘¡$ e observaÃ§Ãµes $ğ‘‚ğ‘¡$, pode ser modelada por uma funÃ§Ã£o de observaÃ§Ã£o:

$ğ‘ƒ(ğ‘‚ğ‘¡âˆ£ğ‘‹ğ‘¡)$

Onde $ğ‘ƒ(ğ‘‚ğ‘¡âˆ£ğ‘‹ğ‘¡)$ representa a probabilidade de o agente observar $ğ‘‚ğ‘¡$ dado que o estado verdadeiro Ã© $ğ‘‹ğ‘¡$.

Exemplos de como os modelos probabilÃ­sticos lidam com estados e observaÃ§Ãµes:

- Modelos Ocultos de Markov (HMM - Hidden Markov Models): Modelam estados ocultos e observaÃ§Ãµes ruidosas ao longo do tempo.

- Redes Bayesianas DinÃ¢micas: ExtensÃ£o das redes Bayesianas para representar a evoluÃ§Ã£o de estados ao longo do tempo.

- POMDPs (Processos de DecisÃ£o Parcialmente ObservÃ¡veis de Markov): Lidam com tomada de decisÃ£o em ambientes incertos e parcialmente observÃ¡veis.

## ReferÃªncias

[1] RUSSELL, Stuart; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3. ed. Upper Saddle River: Prentice Hall, 2010.

[2] MURPHY, Kevin P. Machine Learning: A Probabilistic Perspective. MIT Press, 2012.

[3] BISHOP, Christopher M. Pattern Recognition and Machine Learning. Springer, 2006.