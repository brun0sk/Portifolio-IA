# Inferêmcia

A inferência é o processo de derivar conclusões a partir de um conjunto de premissas ou evidências. Em inteligência artificial e aprendizado de máquina, a inferência pode ser probabilística (baseada em incerteza) ou lógica (baseada em regras e fatos).

## Inferência probabilística

A inferência probabilística trata da estimativa de probabilidades de eventos desconhecidos com base em informações observadas. Em Redes Bayesianas, por exemplo, a inferência é realizada usando a Regra de Bayes e probabilidades condicionais.

Outros exemplos de técnicas de Inferência Probabilística, são:

- Eliminação de Variáveis: Método exato que elimina variáveis irrelevantes para calcular probabilidades marginais.

- Amostragem de Monte Carlo: Métodos aproximados como Gibbs Sampling usam amostragem aleatória para inferência em redes complexas.

- Propagação de Crença (Belief Propagation): Algoritmo eficiente para inferência em redes estruturadas como árvores.

## Inferência Lógica

A inferência lógica baseia-se em regras formais e pode ser dividida em dois tipos principais:

- Inferência Dedutiva: Garante conclusões verdadeiras se as premissas forem verdadeiras. Exemplo: Se "todos os humanos são mortais" e "Sócrates é humano", então "Sócrates é mortal".

- Inferência Indutiva: Generaliza padrões a partir de observações. Exemplo: Se todos os cisnes observados são brancos, inferimos que "todos os cisnes são brancos" (sujeito a erro).

## Referências

[1] RUSSELL, Stuart; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3. ed. Upper Saddle River: Prentice Hall, 2010.

[2] PEARL, Judea. Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann, 1988.

[3] BISHOP, Christopher M. Pattern Recognition and Machine Learning. Springer, 2006.