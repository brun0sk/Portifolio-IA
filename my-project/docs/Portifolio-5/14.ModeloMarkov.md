# Modelos Ocultos de Markov

Os Modelos Ocultos de Markov (Hidden Markov Models - HMMs) são utilizados para modelar processos estocásticos onde um sistema evolui ao longo do tempo, mas seu estado real não pode ser observado diretamente.

Em um HMM, o sistema é representado por:

- Um conjunto de estados ocultos 𝑋𝑡, que não são diretamente observáveis.

- Um conjunto de observações 𝑂𝑡, que dependem probabilisticamente do estado oculto.

- Um modelo de transição $𝑃(𝑋_𝑡∣𝑋_{𝑡−1})$, que define a probabilidade de um estado se transformar em outro ao longo do tempo.

- Um modelo de observação $𝑃(𝑂_𝑡∣𝑋_𝑡)$, que define a relação entre estados ocultos e observações.

A estrutura do modelo é representada como:

$X_1 \to X_2 \to X_3 \to ... \to X_t$

$O_1 \quad O_2 \quad O_3 \quad ... \quad O_t$

1. Definição Formal de um HMM
Um HMM é definido pelo conjunto de cinco elementos:

Conjunto de estados ocultos:

$X = \{X_1, X_2, ..., X_n\}$

Conjunto de observações possíveis:

$O = \{O_1, O_2, ..., O_m\}$

Matriz de transição de estados:

$P(X_t | X_{t-1})$

Matriz de probabilidades de observação:

$P(O_t | X_t)$

Distribuição inicial dos estados:

$P(X_1)$

Cada um desses componentes define a dinâmica do modelo e permite a realização de inferência sobre o estado oculto do sistema.

## Aprendizado em HMMs
O aprendizado em HMMs envolve estimar os parâmetros do modelo, incluindo a matriz de transição 
$𝑃(𝑋𝑡∣𝑋𝑡−1)$ e a matriz de observação $𝑃(𝑂𝑡∣𝑋𝑡)$, a partir de dados não rotulados.

O método mais comum para estimar esses parâmetros é o Algoritmo de Expectation-Maximization (EM), na sua variante conhecida como Baum-Welch. Esse algoritmo ajusta os parâmetros de forma iterativa, maximizando a verossimilhança das observações.

## Referências

[1] RUSSELL, Stuart; NORVIG, Peter. Artificial Intelligence: A Modern Approach. 3. ed. Upper Saddle River: Prentice Hall, 2010.
[2] BISHOP, Christopher M. Pattern Recognition and Machine Learning. Springer, 2006.