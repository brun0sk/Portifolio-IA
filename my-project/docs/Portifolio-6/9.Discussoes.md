# Discussoes

## LIME e SHARP

### LIME

O LIME (Local Interpretable Model-agnostic Explanations) é um aplicativo que possibilita explicar as predições de cada classificador ou regressor de maneira confiável.

A técnica funciona ao aproximar o modelo complexo com um modelo mais simples e interpretável, como uma regressão linear, em torno da previsão que se deseja explicar. Isso é feito perturbando os dados de entrada e observando como as alterações afetam as previsões do modelo. O LIME gera uma explicação local, ou seja, focada em uma única previsão, permitindo que usuários compreendam quais características contribuíram para essa decisão.

### SHARP

O SHAP se baseia na teoria dos jogos, utilizando valores de Shapley para atribuir a cada característica uma importância em relação à previsão de um modelo. 

A principal vantagem do SHAP é que ele fornece uma explicação global e consistente, assegurando que as contribuições de cada característica somem-se à previsão total. Isso significa que o SHAP não apenas identifica quais características são importantes, mas também quantifica o impacto de cada uma de forma aditiva. Essa abordagem permite interpretações mais robustas e comparáveis entre diferentes previsões.

Ambas as técnicas, LIME e SHAP, são utilizadas no XAI, ajudando a desmistificar modelos complexos e a promover a confiança nas decisões automatizadas. Enquanto o LIME foca em explicações locais e interpretáveis, o SHAP oferece uma visão mais abrangente e consistente sobre a contribuição das características, tornando-se uma ferramenta valiosa para a interpretação de modelos de aprendizado de máquina.


## AlphaGo

Como citado na página de tipos de aprendizados por reforço, representam uma boa técnicas para o desenvolvimento de agentes para jogos complexos.

Nesse subtópico será apresentado AlphaGo, o agente que foi capaz de finalmete ganhar de um jogador profissional de GO.

Go é um jogo de tabuleiro Chines, que possui $10^{170}$ combinações possíveis de jogos possíveis, devido a sua alta complexidade, até 2015 (ano da partida entre AlphaGo e Fan Hui) hoje, nenhuma máquina havia sido capaz de ganhar de um profissional, as melhores até o momento, mesmo após decadas de estudo, só chegavam ao nível amador.

O treinamento do agente foi realizado em duas etapas, a primeira o AlphaGo foi exposto a vários jogos de jogadores amadores, para que aprendesse as regras do jogo, após essa fase inicial, o agente foi instruido a jogar várias vezes contra diferêntes versões dele mesmo (aprendizado por reforço).

Após a primeira vitória contra um profissional, em pouco menos um ano depois a AlphaGo foi capaz de ganhar do número um do mundo, Lee Sedol, por 4 jogos a 1.

Em 2017, foi realizado um [documentário](https://www.youtube.com/watch?v=WXuK6gekU1Y) a respeito da trajetória do desenvolvimento da AlphaGo.

## Referências

[1] NIETO JUSCAFRESA, Aleix. Explainable Artificial Intelligence (XAI): A Theoretical and Practical Approach. Trabalho de graduação, Universitat de Barcelona, 2022. Disponível em: https://diposit.ub.edu/dspace/bitstream/2445/192075/1/tfg_nieto_juscafresa_aleix.pdf. 

[2] DEEPMIND. AlphaGo. Disponível em: https://deepmind.google/research/breakthroughs/alphago/. Acesso em: 20 fev. 2025.